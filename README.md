# 🧠 Essay Mentor API

> **FastAPI + Modular Architecture + LLM Adapters (Ollama / GPT-ready)**

A modular FastAPI service designed to **analyze and guide** the writing of short student essays (max. 8,000 characters).

Its goal is to provide automated tools to:

  * **Estimate** whether a text may have been generated by AI.
  * Offer **personalized feedback** based on multiple criteria (originality, creativity, coherence, etc.).
  * **Guide** students with section-specific explanations and writing tips for argumentative essays based on the **Toulmin model** (or similar):
      * *Claim*
      * *Reasoning*
      * *Evidence*
      * *Backing*
      * *Reservation*
      * *Rebuttal*

The project currently uses local models (like Llama 3 through **Ollama**) and can easily connect to GPT models in the future via its adapter layer.

-----

## 🚀 Key Features

  * **Modular architecture** (routers, services, adapters, prompts, models, utils).
  * **Interchangeable LLM adapters** (Ollama, OpenAI, etc.).
  * **Swagger-ready endpoints** (`/analyze`, `/guide`, `/health`).
  * **Configurable prompts** with educational rules (never generate the student’s answer).
  * **Structured feedback** based on customizable evaluation criteria.
  * **Bilingual-ready** (supports both Spanish and English for section names).

-----

## 🧩 Project Structure

```
essay-mentor-api/
├─ app/
│  ├─ main.py
│  ├─ core/config.py
│  ├─ adapters/
│  │  ├─ llm_base.py
│  │  ├─ ollama_adapter.py
│  │  └─ openai_adapter.py
│  ├─ models/
│  │  ├─ types.py            # Section (en/es) and mappings
│  │  ├─ essay.py
│  │  ├─ analyze.py
│  │  └─ guide.py
│  ├─ prompts/factory.py
│  ├─ services/
│  │  ├─ analyzer.py
│  │  └─ guidance.py
│  ├─ routers/
│  │  ├─ analyze.py
│  │  ├─ guide.py
│  │  └─ meta.py
│  └─ utils/json_parse.py
├─ tests/
├─ requirements.txt
├─ .env.example
├─ .gitignore
└─ README.md
```

-----

## ⚙️ Installation

### 1\. Clone the repository

```bash
git clone https://github.com/<your-username>/essay-mentor-api.git
cd essay-mentor-api
```

### 2\. Create virtual environment

```bash
python -m venv .venv
source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
```

### 3\. Install dependencies

```bash
pip install -r requirements.txt
```

### 4\. Configure environment variables

```bash
cp .env.example .env
# Edit values for Ollama or GPT usage
```

-----

## ▶️ Run the API

```bash
uvicorn app.main:app --reload
```

  * **Swagger UI:**
    👉 `http://localhost:8000/docs`
  * **OpenAPI JSON:**
    👉 `http://localhost:8000/openapi.json`

-----

## 🧠 Main Endpoints

| Method | Route | Description |
|:---|:---|:---|
| `GET` | `/health` | Check API health and LLM provider |
| `POST` | `/analyze/ai-likelihood` | Estimate AI-generated likelihood |
| `POST` | `/analyze/feedback` | Generate structured writing feedback |
| `POST` | `/guide` | Provide guidance for essay sections |
| `POST` | `/guide/check-section` | Review a section and suggest improvements |

-----

## 🧩 Example Request

```json
POST /analyze/ai-likelihood
Content-Type: application/json

{
  "text": "This essay argues that empathy plays a key role in education.",
  "section": "claim"
}
```

-----

## 🧰 Technical Requirements

  * Python $\ge$ 3.10
  * FastAPI $\ge$ 0.115
  * **(Optional)** Ollama running locally at `http://localhost:11434`
    ```bash
    ollama pull llama3.1
    ollama serve
    ```

-----

## 🧱 Best Practices

  * Clean Architecture: `routers` → `services` → `adapters` → `models`.
  * Environment-based configuration using `pydantic-settings`.
  * Strong Pydantic validation: character limits, literals, nested models.
  * Robust JSON parsing from LLM responses.
  * Bilingual support (`en`/`es`) for essay sections.
  * No circular dependencies.
  * Ready for Docker or production deployment with `uvicorn`/`gunicorn`.

-----

## 🧪 Unit Testing (Optional)

```bash
pytest -q
```

Recommended to use Httpx for endpoint testing:

```python
from httpx import AsyncClient
from app.main import app

async def test_health():
    async with AsyncClient(app=app, base_url="http://test") as ac:
        res = await ac.get("/health")
        assert res.status_code == 200
```

-----

## 🧭 Development Roadmap

| Phase | Goal |
|:------|:-----|
| A | Base structure, models, routers, healthcheck ✅ |
| B | Implement prompts and utils/json\_parse.py |
| C | LLM adapters (Ollama, OpenAI) |
| D | Services: analyzer.py and guidance.py |
| E | Unit & integration tests |
| F | Dockerfile + CI/CD + deployment |

-----

## 👨‍💻 Author

Fernando Herrera Sánchez
Software Engineer 💡
📍 México
