# ğŸ§  Essay Mentor API

> **FastAPI + Modular Architecture + LLM Adapters (Ollama / GPT-ready)**

A modular FastAPI service designed to **analyze and guide** the writing of short student essays (max. 8,000 characters).

Its goal is to provide automated tools to:

  * **Estimate** whether a text may have been generated by AI.
  * Offer **personalized feedback** based on multiple criteria (originality, creativity, coherence, etc.).
  * **Guide** students with section-specific explanations and writing tips for argumentative essays based on the **Toulmin model** (or similar):
      * *Claim*
      * *Reasoning*
      * *Evidence*
      * *Backing*
      * *Reservation*
      * *Rebuttal*

The project currently uses local models (like Llama 3 through **Ollama**) and can easily connect to GPT models in the future via its adapter layer.

-----

## ğŸš€ Key Features

  * **Modular architecture** (routers, services, adapters, prompts, models, utils).
  * **Interchangeable LLM adapters** (Ollama, OpenAI, etc.).
  * **Swagger-ready endpoints** (`/analyze`, `/guide`, `/health`).
  * **Configurable prompts** with educational rules (never generate the student's answer).
  * **Structured feedback** based on customizable evaluation criteria.
  * **Bilingual-ready**: Configure default language via `DEFAULT_LANGUAGE` env variable (en/es) for all AI responses.

-----

## ğŸ§© Project Structure

```
essay-mentor-api/
â”œâ”€ app/
â”‚  â”œâ”€ main.py
â”‚  â”œâ”€ core/config.py
â”‚  â”œâ”€ adapters/
â”‚  â”‚  â”œâ”€ llm_base.py
â”‚  â”‚  â”œâ”€ ollama_adapter.py
â”‚  â”‚  â””â”€ openai_adapter.py
â”‚  â”œâ”€ models/
â”‚  â”‚  â”œâ”€ types.py            # Section (en/es) and mappings
â”‚  â”‚  â”œâ”€ essay.py
â”‚  â”‚  â”œâ”€ analyze.py
â”‚  â”‚  â””â”€ guide.py
â”‚  â”œâ”€ prompts/factory.py
â”‚  â”œâ”€ services/
â”‚  â”‚  â”œâ”€ analyzer.py
â”‚  â”‚  â””â”€ guidance.py
â”‚  â”œâ”€ routers/
â”‚  â”‚  â”œâ”€ analyze.py
â”‚  â”‚  â”œâ”€ guide.py
â”‚  â”‚  â””â”€ meta.py
â”‚  â””â”€ utils/json_parse.py
â”œâ”€ tests/
â”œâ”€ requirements.txt
â”œâ”€ .env.example
â”œâ”€ .gitignore
â””â”€ README.md
```

-----

## âš™ï¸ Installation

### 1\. Clone the repository

```bash
git clone https://github.com/<your-username>/essay-mentor-api.git
cd essay-mentor-api
```

### 2\. Create virtual environment

```bash
python -m venv .venv
source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
```

### 3\. Install dependencies

```bash
pip install -r requirements.txt
```

### 4\. Configure environment variables

Create a `.env` file in the root directory with the following variables:

```bash
# .env file
APP_NAME=Essay Mentor API
HOST=0.0.0.0
PORT=8000
CORS_ORIGINS=*

# LLM Configuration
LLM_PROVIDER=ollama
LLM_MODEL=llama3.1
OLLAMA_URL=http://localhost:11434

# Default Language (en=English, es=Spanish)
DEFAULT_LANGUAGE=en

# Optional: OpenAI Configuration
OPENAI_API_KEY=your_key_here
OPENAI_MODEL=gpt-4o-mini
```

**Important**: Set `DEFAULT_LANGUAGE` to control the default language for all AI responses (set to "es" for Spanish or "en" for English).

-----

## â–¶ï¸ Run the API

```bash
uvicorn app.main:app --reload
```

  * **Swagger UI:**
    ğŸ‘‰ `http://localhost:8000/docs`
  * **OpenAPI JSON:**
    ğŸ‘‰ `http://localhost:8000/openapi.json`

-----

## ğŸ§  Main Endpoints

| Method | Route | Description |
|:---|:---|:---|
| `GET` | `/health` | Check API health and LLM provider |
| `POST` | `/analyze/ai-likelihood` | Estimate AI-generated likelihood |
| `POST` | `/analyze/feedback` | Generate structured writing feedback |
| `POST` | `/guide` | Provide guidance for essay sections |
| `POST` | `/guide/check-section` | Review a section and suggest improvements |

-----

## ğŸ§© Example Request

```json
POST /analyze/ai-likelihood
Content-Type: application/json

{
  "text": "This essay argues that empathy plays a key role in education.",
  "section": "claim"
}
```

-----

## ğŸ§° Technical Requirements

  * Python $\ge$ 3.10
  * FastAPI $\ge$ 0.115
  * **(Optional)** Ollama running locally at `http://localhost:11434`
    ```bash
    ollama pull llama3.1
    ollama serve
    ```

-----

## ğŸ§± Best Practices

  * Clean Architecture: `routers` â†’ `services` â†’ `adapters` â†’ `models`.
  * Environment-based configuration using `pydantic-settings`.
  * Strong Pydantic validation: character limits, literals, nested models.
  * Robust JSON parsing from LLM responses.
  * Bilingual support (`en`/`es`) for essay sections.
  * No circular dependencies.
  * Ready for Docker or production deployment with `uvicorn`/`gunicorn`.

-----

## ğŸ§ª Testing

The project includes comprehensive test coverage with pytest.

### Run Tests

```bash
# Run all tests
pytest

# Run with verbose output
pytest -v

# Run with coverage report
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_services_analyzer.py

# Run specific test
pytest tests/test_services_analyzer.py::TestAnalyzeAILikelihood::test_analyze_ai_likelihood_success
```

### Test Coverage

The test suite includes:

- **Unit Tests**: Services, adapters, utilities
- **Integration Tests**: API endpoints
- **Fixtures**: Mock responses for LLM calls

**Test Files:**
- `tests/test_adapters_llm.py` - LLM adapter tests
- `tests/test_services_analyzer.py` - Analysis service tests
- `tests/test_services_guidance.py` - Guidance service tests
- `tests/test_utils_json_parse.py` - JSON parsing utilities tests
- `tests/test_utils_criteria.py` - Criteria utilities tests
- `tests/test_utils_text_format.py` - Text formatting utilities tests
- `tests/test_routers_integration.py` - API endpoints integration tests
- `tests/conftest.py` - Shared fixtures and configuration

**Current Status:** âœ… 104 tests passing

### Example Test

```python
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_health_endpoint():
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "ok"
```

-----

## ğŸ§­ Development Roadmap

| Phase | Goal |
|:------|:-----|
| A | Base structure, models, routers, healthcheck âœ… |
| B | Implement prompts and utils/json\_parse.py âœ… |
| C | LLM adapters (Ollama, OpenAI) âœ… |
| D | Services: analyzer.py and guidance.py âœ… |
| E | Unit & integration tests âœ… |
| F | Dockerfile + CI/CD + deployment | optional

-----

## ğŸ‘¨â€ğŸ’» Author

Fernando Herrera SÃ¡nchez
Software Engineer ğŸ’¡
ğŸ“ MÃ©xico
